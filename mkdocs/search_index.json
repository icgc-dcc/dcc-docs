{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to ICGC Docs\n\n\nThis is the official project documentation site of the ICGC.\n\n\nContents\n\n\n\n\nPortal\n\n\nCloud\n\n\nSubmission\n\n\n\n\nContact\n\n\nFor support, please contact us at \ndcc-support@icgc.org\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-icgc-docs", 
            "text": "This is the official project documentation site of the ICGC.", 
            "title": "Welcome to ICGC Docs"
        }, 
        {
            "location": "/#contents", 
            "text": "Portal  Cloud  Submission", 
            "title": "Contents"
        }, 
        {
            "location": "/#contact", 
            "text": "For support, please contact us at  dcc-support@icgc.org .", 
            "title": "Contact"
        }, 
        {
            "location": "/portal/about/", 
            "text": "About\n\n\nOverview\n\n\nThis is the Portal documentation page", 
            "title": "About"
        }, 
        {
            "location": "/portal/about/#about", 
            "text": "", 
            "title": "About"
        }, 
        {
            "location": "/portal/about/#overview", 
            "text": "This is the Portal documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/portal/analysis/", 
            "text": "Analysis\n\n\nOverview\n\n\nThis is the Analysis documentation page", 
            "title": "Analysis"
        }, 
        {
            "location": "/portal/analysis/#analysis", 
            "text": "", 
            "title": "Analysis"
        }, 
        {
            "location": "/portal/analysis/#overview", 
            "text": "This is the Analysis documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/portal/api/", 
            "text": "API\n\n\nOverview\n\n\nThis is the API documentation page", 
            "title": "API"
        }, 
        {
            "location": "/portal/api/#api", 
            "text": "", 
            "title": "API"
        }, 
        {
            "location": "/portal/api/#overview", 
            "text": "This is the API documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/portal/publication/", 
            "text": "Publication\n\n\nOverview\n\n\nThis is the Publication documentation page", 
            "title": "Publication"
        }, 
        {
            "location": "/portal/publication/#publication", 
            "text": "", 
            "title": "Publication"
        }, 
        {
            "location": "/portal/publication/#overview", 
            "text": "This is the Publication documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/portal/releases/", 
            "text": "Releases\n\n\nOverview\n\n\nThis is the Releases documentation page", 
            "title": "Releases"
        }, 
        {
            "location": "/portal/releases/#releases", 
            "text": "", 
            "title": "Releases"
        }, 
        {
            "location": "/portal/releases/#overview", 
            "text": "This is the Releases documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/portal/search/", 
            "text": "Search\n\n\nOverview\n\n\nSearch is a core component of the Portal", 
            "title": "Search"
        }, 
        {
            "location": "/portal/search/#search", 
            "text": "", 
            "title": "Search"
        }, 
        {
            "location": "/portal/search/#overview", 
            "text": "Search is a core component of the Portal", 
            "title": "Overview"
        }, 
        {
            "location": "/portal/software/", 
            "text": "Software\n\n\nOverview\n\n\nThis is the Software documentation page\n\n\nRelease Notes\n\n\nChanges in Data Portal Software Release 3.8.20 - Nov 27, 2015\n\n\n\n\nAdded Drug/Compound entity page which correlates targeted genes and provides context into clinical trials, e.g. Go to Sprycel Compound page ()\n\n\nAdded Drug/Compound section in Gene Entity Page, e.g. Go to Compound section in EGFR Gene page ()\n\n\nAdded Quick Search support for Drug/Compound, e.g. Type Leukeran in the Quick Search\n\n\nIobio integration added to aligned BAM files stored in AWS/Collaboratory, e.g. Go to BAM Stats section in\n\n\nAdded highlight of genes overlapping with Enrichement Analysis input genes in Pathway Viewer, e.g. Look for R-HSA-5654716 Pathway Viewer in\n\n\n\n\nChanges in Data Portal Software Release 3.8.18.3 - Nov 18, 2015\n\n\n\n\nReleased ICGC in the Cloud (), see Amazon post:\n\n\nDisplayed User Guide to explore and analyze ICGC data stored in Amazon AWS and Collaboratory ()\n\n\nSeparated DCC data releases () from Data Repositories ()\n\n\nRe-organized filters and added Analysis Software filter on Data Repositories browser\n\n\nImproved performance of the Advanced Search page\n\n\nVarious Bug fixes\n\n\n\n\nChanges in Data Portal Software Release 3.8.16.1 - Oct 28, 2015\n\n\n\n\nDisplayed Pathway Viewer from Reactome Pathway Entity Page, (e.g. , click on \"Pathway Viewer\" section in the navigation bar: mutated genes are highlighted and mutation count is displayed at the top-right corner of the entity. User should click on entity to view details about genes and mutation count)\n\n\nDisplayed Pathway Viewer from an Enrichment Analysis for all the enriched gene sets (e.g. , click on \"Open in Pathway Viewer\" and navigate through the reactome pathways to view pathway diagrams)\n\n\nEnhanced data repositories, e.g. assigned a File ID FI99999, added Specimen Type facet (link: )\n\n\nUpdated File Entity Page layout (e.g. )\n\n\nWhen navigating from Donor Entity page to Genome Viewer, the mutation sorting and filter is now carried over\n\n\nSignificantly reduced the load time of stacked bar chart in Project Summary page ()\n\n\nRefactored Browser API to fix various problems that could result in error 500s being returned\n\n\nBug fixes for Project Sample Sheet, Pie Chart colouring\n\n\n\n\nChanges in Data Portal Software Release 3.8.14.4 - Sept 22, 2015\n\n\n\n\nAdded functionality to view files in external repositories based on filters from advanced search (Go to , select your filters then in Donor tab click on \"View in External Repositories\" ). Documentation is available here:\n\n\nAdded functionality to download donor data and view donor sets in external repositories browser from Data Analysis (icons are available for saved donor sets here: )\n\n\nAdded functionality to upload a donor set in Donor facet in Advanced Search () and External Repositories browser ()\n\n\nAdded full screen support for Genome Viewer\n\n\nAdded Tumor Types facet in Projects page ()\n\n\nBug fixes for gene query in the case of no donor analysis and for Pathway Viewer\n\n\n\n\nChanges in Data Portal Software Release 3.8.9.3 - July 3, 2015\n\n\n\n\nAdded PCAWG section to home page and footer\n\n\nAdded PCAWG page -\n\n\nMinor bug fixes\n\n\n\n\nChanges in Data Portal Software Release 3.8.8.0 - June 16, 2015\n\n\n\n\nAdded DCC - \nExternal Repository feature\n. User can search for ICGC-Donor files stored in external repository and create a manifest to download them. Documentation is available here:\n\n\nAdded Study facet to filter PCAWG (Pan-Cancer Analysis of Whole Genome) Donors in Advanced Search - Donor tab, e.g. \n PCAWG Donors in Advanced Search \n\n\nAdded support for clinical supplementary files (family, exposure, therapy). Displayed in Donor Entity Page and exported in Donors files\n\n\nAdded support for pending donors and projects. Documentation is available here:\n\n\nAdded preliminary UI / API support for \"donor states\". API documentation available here:\n\n\nReduced project colour space to primary sites\n\n\nBug fixes and core javascript libraries upgrades\n\n\n\n\nChanges in Data Portal Software Release 3.8.2.3 - April 7, 2015\n\n\n\n\nRedesigned Data Analysis feature to improve user experience (). Documentation available here:\n\n\nAdded demo analyses: User can launch them from\n\n\nAdded Phenotype Comparison analysis to Data Analysis feature ()\n\n\nAdded functionality to upload a custom gene set and save it in Data Analysis (). User can then perform analysis on saved gene set\n\n\nAdded version control and version deprecation for data analyses: User will get a warning message on his analyses if ICGC data has been updated\n\n\nBug fixes and libraries upgrade\n\n\n\n\nChanges in Data Portal Software Release 3.8.2.2 - March 16, 2015\n\n\n\n\nAdded new visualization to show \"Donor Count History\" ()\n\n\nBug fixes\n\n\n\n\nChanges in Data Portal Software Release 3.7.6.6 - February 11, 2015\n\n\n\n\nAdded \"GA4GH Beacon\" feature ()\n\n\nAdded \"Saved Sets\" feature ()\n\n\nAdded \"Set Analysis\" feature ()\n\n\nAdded \"Enrichment Analysis\" feature ()\n\n\nProjects page layout update and optimization ()\n\n\nVarious bug fixes\n\n\n\n\nChanges in Data Portal Software Release 3.7.6.2 - January 21, 2015\n\n\n\n\n\"Gene Ontology\" quick search ()\n\n\n\"Gene Ontology\" advanced search (\nhttps://dcc.icgc.org/search/g?filters=%7B%22gene%22%3A%7B%22goTermId%22%...\n)\n\n\n\"Gene Ontology\" entity pages (see )\n\n\nUpdated \"Reactome Pathway\" data (see )\n\n\nUpdate \"Cancer Gene Census\" data (see )\n\n\nGeneralized \"Pathway\", \"Cancer Gene Census\" and \"Gene Ontology\" into unified \"Gene Set\" integration\n\n\nVarious small fixes\n\n\n\n\nChanges in Data Portal Software Release 3.7.4.1 - December 3, 2014\n\n\n\n\nAdded new visualization showing \"Number of Somatic Mutations in Donor's Exomes Across Cancer Projects\" (see )\n\n\nUsers can now upload their own custom gene list in Advanced Search (see )\n\n\nAdded Markdown support for data repository for inline viewing of README files (see )\n\n\nImproved general client-side page responsiveness of chart rendering\n\n\nMinor bug fixes\n\n\n\n\nChanges in Data Portal Software Release 3.5.12 - September 29, 2014\n\n\n\n\nFixed bug wherein a DACO authorization was being denied to ICGC.org (non-OpenID) users with granted access\n\n\nImproved general client-side page responsiveness\n\n\n\n\nChanges in Data Portal Software Release 3.5 - September 12, 2014\n\n\n\n\nUpgraded to Genome Maps 1.1.7\n\n\nImproved site performance through better caching\n\n\nAdded \"Multiple Observations per Donor Mutation Occurrence\" feature\n\n\nAdded \"Short URL\" feature\n\n\nAdded \"Repository URL Right-click to Copy\" feature\n\n\n\n\nChanges in Data Portal Software Release 3.2 - May 15, 2014\n\n\n\n\nAdded \"Aggregated SSM VCF\" feature\n\n\nAdded \"Pathway Entity Page\" feature\n\n\nAdded \"Pathway Search\" feature\n\n\nAdded \"Gene Sets\" feature\n\n\nAdded \"Functional Impact\" feature\n\n\nAdded \"Project Search\" feature\n\n\nAdded \"Authentication and Authorization\" feature\n\n\nAdded \"Controlled Access Download\" feature\n\n\nAdded \"Asynchronous Download\" feature\n\n\nAdded \"Public RESTful API\" feature\n\n\n\n\n\u2039 ICGC Publication Guidelines\n \nup\n \nMethods \u203a\n\n\n\n\nInternational Cancer Genome Consortium (ICGC)\n\n\nCancer Genome Projects\n\n\nCommittees and Working Groups\n\n\nPolicies and Guidelines\n\n\nMedia\n\n\n\n\n\n\nICGC Data Portal (DCC)\n\n    *\n\n\nDCC Cancer Projects\n\n\nDCC Advanced Search\n\n\nDCC Data Repository\n\n\nDCC Documentation\n\n\n\n\n\n\nData Access Compliance Office (DACO)\n\n\nAccess Forms\n\n\nResearch Practices\n\n\nInternational Data Access Committee\n\n\nDACO Approved Projects\n\n\n\n\n\n\nContact Us\n\n\ninfo@icgc.org\n\n\nTerms \n Conditions\n | \nPrivacy Policy\n\n\n\u00a9 2012 \nInternational Cancer Genome Consortium\n. All rights reserved.\n\n\n\n\n\n\nFor ICGC Data Portal (DCC) submission support, please contact:  \ndcc-support@icgc.org\n\n\n This site is connected with the \nCentral User Directory\n.", 
            "title": "Software"
        }, 
        {
            "location": "/portal/software/#software", 
            "text": "", 
            "title": "Software"
        }, 
        {
            "location": "/portal/software/#overview", 
            "text": "This is the Software documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/portal/software/#release-notes", 
            "text": "Changes in Data Portal Software Release 3.8.20 - Nov 27, 2015   Added Drug/Compound entity page which correlates targeted genes and provides context into clinical trials, e.g. Go to Sprycel Compound page ()  Added Drug/Compound section in Gene Entity Page, e.g. Go to Compound section in EGFR Gene page ()  Added Quick Search support for Drug/Compound, e.g. Type Leukeran in the Quick Search  Iobio integration added to aligned BAM files stored in AWS/Collaboratory, e.g. Go to BAM Stats section in  Added highlight of genes overlapping with Enrichement Analysis input genes in Pathway Viewer, e.g. Look for R-HSA-5654716 Pathway Viewer in   Changes in Data Portal Software Release 3.8.18.3 - Nov 18, 2015   Released ICGC in the Cloud (), see Amazon post:  Displayed User Guide to explore and analyze ICGC data stored in Amazon AWS and Collaboratory ()  Separated DCC data releases () from Data Repositories ()  Re-organized filters and added Analysis Software filter on Data Repositories browser  Improved performance of the Advanced Search page  Various Bug fixes   Changes in Data Portal Software Release 3.8.16.1 - Oct 28, 2015   Displayed Pathway Viewer from Reactome Pathway Entity Page, (e.g. , click on \"Pathway Viewer\" section in the navigation bar: mutated genes are highlighted and mutation count is displayed at the top-right corner of the entity. User should click on entity to view details about genes and mutation count)  Displayed Pathway Viewer from an Enrichment Analysis for all the enriched gene sets (e.g. , click on \"Open in Pathway Viewer\" and navigate through the reactome pathways to view pathway diagrams)  Enhanced data repositories, e.g. assigned a File ID FI99999, added Specimen Type facet (link: )  Updated File Entity Page layout (e.g. )  When navigating from Donor Entity page to Genome Viewer, the mutation sorting and filter is now carried over  Significantly reduced the load time of stacked bar chart in Project Summary page ()  Refactored Browser API to fix various problems that could result in error 500s being returned  Bug fixes for Project Sample Sheet, Pie Chart colouring   Changes in Data Portal Software Release 3.8.14.4 - Sept 22, 2015   Added functionality to view files in external repositories based on filters from advanced search (Go to , select your filters then in Donor tab click on \"View in External Repositories\" ). Documentation is available here:  Added functionality to download donor data and view donor sets in external repositories browser from Data Analysis (icons are available for saved donor sets here: )  Added functionality to upload a donor set in Donor facet in Advanced Search () and External Repositories browser ()  Added full screen support for Genome Viewer  Added Tumor Types facet in Projects page ()  Bug fixes for gene query in the case of no donor analysis and for Pathway Viewer   Changes in Data Portal Software Release 3.8.9.3 - July 3, 2015   Added PCAWG section to home page and footer  Added PCAWG page -  Minor bug fixes   Changes in Data Portal Software Release 3.8.8.0 - June 16, 2015   Added DCC -  External Repository feature . User can search for ICGC-Donor files stored in external repository and create a manifest to download them. Documentation is available here:  Added Study facet to filter PCAWG (Pan-Cancer Analysis of Whole Genome) Donors in Advanced Search - Donor tab, e.g.   PCAWG Donors in Advanced Search   Added support for clinical supplementary files (family, exposure, therapy). Displayed in Donor Entity Page and exported in Donors files  Added support for pending donors and projects. Documentation is available here:  Added preliminary UI / API support for \"donor states\". API documentation available here:  Reduced project colour space to primary sites  Bug fixes and core javascript libraries upgrades   Changes in Data Portal Software Release 3.8.2.3 - April 7, 2015   Redesigned Data Analysis feature to improve user experience (). Documentation available here:  Added demo analyses: User can launch them from  Added Phenotype Comparison analysis to Data Analysis feature ()  Added functionality to upload a custom gene set and save it in Data Analysis (). User can then perform analysis on saved gene set  Added version control and version deprecation for data analyses: User will get a warning message on his analyses if ICGC data has been updated  Bug fixes and libraries upgrade   Changes in Data Portal Software Release 3.8.2.2 - March 16, 2015   Added new visualization to show \"Donor Count History\" ()  Bug fixes   Changes in Data Portal Software Release 3.7.6.6 - February 11, 2015   Added \"GA4GH Beacon\" feature ()  Added \"Saved Sets\" feature ()  Added \"Set Analysis\" feature ()  Added \"Enrichment Analysis\" feature ()  Projects page layout update and optimization ()  Various bug fixes   Changes in Data Portal Software Release 3.7.6.2 - January 21, 2015   \"Gene Ontology\" quick search ()  \"Gene Ontology\" advanced search ( https://dcc.icgc.org/search/g?filters=%7B%22gene%22%3A%7B%22goTermId%22%... )  \"Gene Ontology\" entity pages (see )  Updated \"Reactome Pathway\" data (see )  Update \"Cancer Gene Census\" data (see )  Generalized \"Pathway\", \"Cancer Gene Census\" and \"Gene Ontology\" into unified \"Gene Set\" integration  Various small fixes   Changes in Data Portal Software Release 3.7.4.1 - December 3, 2014   Added new visualization showing \"Number of Somatic Mutations in Donor's Exomes Across Cancer Projects\" (see )  Users can now upload their own custom gene list in Advanced Search (see )  Added Markdown support for data repository for inline viewing of README files (see )  Improved general client-side page responsiveness of chart rendering  Minor bug fixes   Changes in Data Portal Software Release 3.5.12 - September 29, 2014   Fixed bug wherein a DACO authorization was being denied to ICGC.org (non-OpenID) users with granted access  Improved general client-side page responsiveness   Changes in Data Portal Software Release 3.5 - September 12, 2014   Upgraded to Genome Maps 1.1.7  Improved site performance through better caching  Added \"Multiple Observations per Donor Mutation Occurrence\" feature  Added \"Short URL\" feature  Added \"Repository URL Right-click to Copy\" feature   Changes in Data Portal Software Release 3.2 - May 15, 2014   Added \"Aggregated SSM VCF\" feature  Added \"Pathway Entity Page\" feature  Added \"Pathway Search\" feature  Added \"Gene Sets\" feature  Added \"Functional Impact\" feature  Added \"Project Search\" feature  Added \"Authentication and Authorization\" feature  Added \"Controlled Access Download\" feature  Added \"Asynchronous Download\" feature  Added \"Public RESTful API\" feature   \u2039 ICGC Publication Guidelines   up   Methods \u203a   International Cancer Genome Consortium (ICGC)  Cancer Genome Projects  Committees and Working Groups  Policies and Guidelines  Media    ICGC Data Portal (DCC) \n    *  DCC Cancer Projects  DCC Advanced Search  DCC Data Repository  DCC Documentation    Data Access Compliance Office (DACO)  Access Forms  Research Practices  International Data Access Committee  DACO Approved Projects    Contact Us  info@icgc.org  Terms   Conditions  |  Privacy Policy  \u00a9 2012  International Cancer Genome Consortium . All rights reserved.    For ICGC Data Portal (DCC) submission support, please contact:   dcc-support@icgc.org   This site is connected with the  Central User Directory .", 
            "title": "Release Notes"
        }, 
        {
            "location": "/cloud/about/", 
            "text": "About\n\n\nOverview\n\n\nThis is the Portal documentation page", 
            "title": "About"
        }, 
        {
            "location": "/cloud/about/#about", 
            "text": "", 
            "title": "About"
        }, 
        {
            "location": "/cloud/about/#overview", 
            "text": "This is the Portal documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/cloud/guide/", 
            "text": "Overview\n\n\nThis user guide describes the steps to securely explore and analyze ICGC data stored in \nAmazon (\nAWS\n)\n or \nCollaboratory (\nOpenStack\n)\n cloud environments. For more information about ICGC cloud initiatives, please see \nICGC in the Cloud\n.\n\n\nPlease see \nTerms\n for a glossary of terms used in this guide.\n\n\nProcess\n\n\nThe figure below illustrates the overall process and systems involved:\n\n\n\n\nAuthorization\n\n    Apply for DACO \nCloud Access\n if not already approved\n    Upon approval, login to the \nData Portal\n\n    Generate an \nAccess Token\n for cloud download\n\n\nCompute Prerequistes\n\n    Provision a \nCompute Instance\n in the target cloud\n\n\nInstallation\n\n    Download and install the ICGC \nStorage Client\n\n\nConfiguration\n\n    Configure the Storage Client to use the generated Access Token\n\n\nFile Search\n\n    Identify files of interest using the Data Portal\n\n\nStorage Client Usage\n\n    Download or view data with the provided Storage Client or via an external tool\n\n\n\n\n\n\nThe subsequent sections will provide additional details on each of these topics.\n\n\nSecurity\n\n\nThe usage of the distributed \nStorage Client\n is required to provide additional security while operating in participating cloud environments and to enhance user download speeds.\n\n\nAWS\n\n\nSecurity is enforced by a coordinating ICGC storage server. The client communicates with the server which brokers downloads and converts ICGC Access Tokens into Amazon \npre-signed urls\n. Once a successful authorization handshake between the client and the server is established, downloads will be transferred directly from \nS3\n to the client, maintaining fast access to the data.\n\n\nIt is important to note that the provided software only functions within the \nus-east-1\n EC2 region of AWS located in Northern Virginia, U.S. where the data is physically stored. Attempting to use the software outside of this region will be denied data access.\n\n\nCollaboratory\n\n\nDownloads only function inside Collaboratory's OpenStack environment.\n\n\nLastly, it is the user\u2019s responsibility to protect the data after it has been attained. This includes any subsequent analyses and storage on cloud and downstream resources.\n\n\nAuthorization\n\n\nThere are two prerequesites to using the Storage Client: DACO Cloud Access status and a self-provisioned Access Token.\n\n\nDACO Cloud Access\n\n\nDACO Cloud Access is prerequisite to using the Storage Client. To apply for DACO access please follow the instructions provided at \nhttps://icgc.org/daco\n. Once approved, you will be able to \nlogin\n to the Data Portal to generate an \nAccess Token\n. To login, click on the \u201cLogin\u201d link in the upper right-hand corner of the page. When prompted, choose to login with either your \nICGC.org login\n or one of the supported OpenID providers (e.g. Google). After successful authentication, you will know that you have Cloud Access to the controlled tier if the \u201clogin\u201d link is replaced with a green cloud icon ().\n\n\nAccess Tokens\n\n\nThe Access Token model used for protecting the cloud data set follows a similar process to Github\u2019s \npersonal access tokens\n. Tokens are used instead of a username / password to securely access ICGC resources.\n\n\nRelated to Access Tokens is the concept of \nScopes\n. Tokens allow you to associate Scopes which limit access to that needed for the target environment. This enhances security by following the \nPrinciple of Least Privilege\n. Cloud specific Scopes will become available after acquiring DACO Cloud Access. An instance of a cloud download token will grant access to all of the available data in that environment.\n\n\nToken Manager\n\n\nTo acquire an Access Token, you must first obtain DACO Clould Access and login to the Data Portal. After a successful login, there will be \nToken Manager\n link in the upper right corner of the page. Clicking on this link will display the Token Manager dialog:\n\n\n\n\nFrom this dialog, you can manage the Access Tokens associated with your account. Importantly, you may delete and regenerate an access token if you believe that it has been compromised.\n\n\n\n\nWhen creating an Access Token, you will need to specify the Scope associated with the target cloud(s).\n\n\nAWS\n\n\nIn the case of the ICGC AWS data set, an access token with the \naws.download\n scope is required to access the \ncontrolled access data\n\n\nCollaboratory\n\n\nIn the case of the ICGC Collaboratory data set, an access token with the \ncollab.download\n scope is required to access the \ncontrolled access data\n\n\nYou can verify that your Access Token has the desired scopes by inspecting it in the table at the bottom of the dialog. For security purposes, Access Tokens must remain private and not be shared with anyone.\n\n\nFollowing the creation of a Compute Instance, discussed in the next section, you will need to edit the Storage Client client configuration file to include the generated Access Token. See the \nConfiguration\n section for additional information.\n\n\nCompute Prerequisites\n\n\nCompute Instance\n\n\nAs a first step in analyzing data, you will need to create a Compute Instance to run the Storage Client and any other supporting software.\n\n\nAWS\n\n\nIn order to run within \nEC2\n, you will need your own AWS account to provision a running EC2 instance. Any data processing will be charged to this account. Note that ICGC data download from S3 to the same EC2 region is free of charge. Please see Amazon's documentation for detailed instructions.\n\n\nCollaboratory\n\n\nIn order to run within \nCollaboratory\n, you will need to be enrolled. To begin the enrollment process, please send an email to \nhelp@cancercollaboratory.org\n.\n\n\nThe following sections provide guidance on selecting and configuring the chosen instance type.\n\n\nResources\n\n\nAs data files are quite large, users should have enough local disk space to store files downloaded from the remote repository.\n\n\nMore processing cores will give greater parallelism, and therefore, better thoughput of downloads.\n\n\nBy default the storage client is configured to use a maximum of 3G of RAM. Most of time this is more than sufficient.\n\n\nOperating System\n\n\nThe Storage Client has been designed to work on modern Mac and Linux distributions. Windows should work as well but remains untested.\n\n\nDependencies\n\n\nThe Storage Client requires Java 8 to be installed. It has been tested using the Oracle distribution. The procedure for installing Java 8 will vary depending on the operating system and package manager used.\n\n\nIn order to use the mount feature, \nFUSE\n is required. On most Linux based systems this will require installing \nlibfuse-dev\n and \nfuse\n packages.\n\n\nInstallation\n\n\nThis section describes how to install the Storage Client. The are two options: (a) from a tarball and (b) from a Docker image hosted on Dockerhub.\n\n\nInstall from Tarball\n\n\nTo begin using the Storage Client, the first step is to download the distribution. The latest version can be downloaded from \nhere\n.\n\n\nwget -O icgc-storage-client.tar.gz https://dcc.icgc.org/api/v1/ui/software/icgc-storage-client/latest\ntar -xvzf icgc-storage-client.tar.gz\n\n\n\n\nAfter untaring the archive, the Storage Client will be available at \nbin/icgc-storage-client\n. Steps to verify the authenticity and integrity of the download can be found on our \nsoftware\n page.\n\n\nInstall from Docker Image\n\n\nWe also support a Docker image of the Storage Client that is bundled with Java 8 for easy deployment.\n\n\nThe image is hosted at \nhttps://hub.docker.com/r/icgc/icgc-storage-client/\n and downloaded by issuing the following command:\n\n\ndocker pull icgc/icgc-storage-client\n\n\n\n\nOnce pulled, you can open a shell in the container by executing:\n\n\ndocker run -it icgc/icgc-storage-client\n\n\n\n\nThere is no entry point or command defined for the image. The software may be located at \n/icgc/icgc-storage-client\n which is also the working directory of the container. All other steps for \nusing the Storage Client\n will be the same for both Docker and tarball installations.\n\n\nConfiguration\n\n\nThe configuration of the Storage Client is stored in the \nconf/application.properties\n file of the distribution.\n\n\nAccess Configuration\n\n\nThe main configuration element is the access token generated in \nAccess Token\n above. Configuration is stored in the \nconf/\n directory of the distribution.\n\n\nEdit \napplication.properties\n and add the generated accesss token to the line:\n\n\naccessToken=access token\n\n\n\n\nWhen using Docker, this can also be set with an environmental variable:\n\n\ndocker run -it -e ACCESSTOKEN=access token icgc/icgc-storage-client\n\n\n\n\nCollaboratory\n\n\nIn addition to the above, you will need to change the \nbin/icgc-storage-client\n script to set \nSTORAGE_PROFILE=collab\n. This can also performed externally via the environmental variable of the same name. Note that it is also possible to override this per execution using \nbin/icgc-storage-client\n's \n--profile collab\n argument.\n\n\nTransport Configuration\n\n\nBased on the target Compute Instance defined in \nCompute Prerequisites\n and transfer speed requirements, it may be necessary to make changes to how the Storage Client transfers data. This is achieved by setting \ntransport.parallel\n and \ntransport.memory\n:\n\n\n\n\ntransport.parallel\n controls the number of concurrent threads for multi-part data transfers. It is recommended to set this to the number of cores of the Compute Instance.\n\n\ntransport.memory\n is the amount of non-heap memory per thread, in gigabytes. It is recommended set this to a value of \n1\n (1 GB). Be sure to leave enough memory for the operating system and any other software that may be running on the Compute Instance.\n\n\n\n\nFile Search\n\n\nFinding files of interest can be done via the Data Portal. Objects are identified by their \nObject ID\n.\n\n\n\n\nNavigate to \nrepository file search\n\n\nClick on the \nAWS\n or \nCollaboratory\n filter in the left hand pane\n\n\nFilter based on properties of interest (e.g. donor id, specimen id, etc.)\n\n\nExport a \nManifest\n for future use with the Storage Client\n\n\n\n\nThe Manifest is the main way to define what files should be downloaded by the Storage Client. However, knowing the Object ID is sufficient for a single file download. To generate a Manifest, click on the \"Download manifests\" link the the Data Repository browser. You will be prompted with a \"Download manifests\" dialog:\n\n\n\n\nManifests downloaded from the Data Portal can be transferred to the Storage Client instance by using SFTP or SCP. For convenience, it is also possible to use a Manifest ID saved on the Data Portal by clicking on the \"Manifest ID\" button. See the \nStorage Client Usage\n section for usage information.\n\n\nStorage Client Usage\n\n\nThis section provides information on how to use the Storage Client once it has been properly downloaded and configured. It assumes the user possesses and has configured the requisite access token discussed previously.\n\n\nThe Storage Client has the general syntax:\n\n\nicgc-storage-client [options] [command] [command options]\n\n\n\n\nIt offers a set of commands, where each command has its own set of options to influence its operation.\n\n\nHelp\n\n\nThe Storage Client provides a \n--help\n option to list the available commands and a brief description of their supported options:\n\n\nbin/icgc-storage-client --help\n\n\n\n\nIt is also possible to get information on a specific command using the \nhelp\n command:\n\n\nbin/icgc-storage-client help download\n\n\n\n\nURL Command\n\n\nThe \nurl\n command is the most basic command supported by the Storage Client. It allows one to resolve the underyling S3 URL for the requested object. This is useful if one wants to directly access the URL via HTTPS with an external client or tool (e.g. \ncurl\n, \nwget\n, etc.)\n\n\nbin/icgc-storage-client url --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd\n\n\n\n\nAn example of using \nwget\n:\n\n\nbin/icgc-storage-client url --object-id Object ID\nResolving URL for object: ddcdd044-adda-5f09-8849-27d6038f8ccd (offset = 0, length = -1)\nhttps://s3-external-1.amazonaws.com/snip\n\n\nwget https://s3-external-1.amazonaws.com/snip\n\n\n\n\n\nDownload Command\n\n\nThe \ndownload\n command allows fast parallel download of remote objects. It can be run in one of two modes: (a) single object mode and (b) Manifest driven mode\n\n\nNote that the Storage Client is able to resume an interrupted download session. Simply rerun the same command again and it will continue.\n\n\nSingle Object\n\n\nThis mode is most useful when downloading a single object given a known Object ID, perhaps acquired from the Data Portal:\n\n\nbin/icgc-storage-client download --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd --output-dir data\n\n\n\n\nDownloads will be stored in the \n--output-dir\n.\n\n\nManifest\n\n\nUsing a Manifest is ideal for downloading multiple files identified through the Data Portal. The \nrepository file search\n allows one to generate a Manifest file that can be supplied for bulk downloading files. It also provides some additional metadata for selected files that gives the donor, specimen and sample context.\n\n\nbin/icgc-storage-client download --manifest manifest.txt --output-dir data\n\n\n\n\nThe optional \n--output-layout\n option can be used to organize the downloads into a couple of predefined directory layouts. See the \n--help\n for addional information.\n\n\nManifest Command\n\n\nThe \nmanifest\n command allows a user to quickly view the contents of a download Manifest produced by the Data Portal. A Manifest can come from:\n\n\n\n\nThe local file system\n\n\nA Manifest ID that is hosted on the Data Portal\n\n\nAny URL\n\n\n\n\nA Manifest is a TSV file that contains both file identifying fields and satellite metadata for understanding the relationships to other data including donor, project and study.\n\n\nManifest from a Local File\n\n\nAn example of using a local file system Manifest:\n\n\nbin/icgc-storage-client manifest --manifest manifest.aws-virginia.1444232116728.txt\n\n\n\n\nManifest from the Data Portal\n\n\nAn example of using a Data Portal hosted Manifest:\n\n\nbin/icgc-storage-client manifest --manifest 49e91614-7811-11e5-8a58-34363bcf803c\n\n\n\n\nManifest from a URL\n\n\nAn example of using a URL hosted Manifest:\n\n\nbin/icgc-storage-client manifest --manifest http://hastebin.com/raw/ujajodilih\n\n\n\n\nView Command\n\n\nThe \nview\n command is a minimal version of \nsamtools view\n. It allows to request a \u201cgenomic slice\u201d of the remote BAM file, freeing the user from having to download the entire file locally, saving bytes and time.\n\n\nThe following example will download reads overlapping the region 1 - 100000 in chromosome 1:\n\n\nbin/icgc-storage-client view --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd --query 1:1-100000\n\n\n\n\nThe BAI is automatically discovered and streamed as part of the operation.\n\n\nFor quickly accessing the only the BAM header one can issue:\n\n\nbin/icgc-storage-client view --header-only --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd\n\n\n\n\nIt is also possible to pipe the output of the above to \nsamtools\n, etc. for pipelining a workflow:\n\n\nbin/icgc-storage-client view --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd | samtools mpileup -\n\n\n\n\nMount Command\n\n\nThe \nmount\n command can be used to mount the remote S3 bucket as a read-only \nFUSE\n file system. This is very useful to browse and explore the available files, as well as quickly see their size and date of modification using common commands such as \nls\n, \nfind\n, \ndu\n and \ntree\n. It also works very well with standard analysis tools such as \nsamtools\n.\n\n\nFiles are organized into a virtual directory structure. The following shows the default \nbundle\n layout:\n\n\n/bundleId1/fileName1\n/bundleId1/fileName2\n...\n/bundleId1/fileNamei\n...\n/bundleIdn/fileName1\n/bundleIdn/fileName2\n...\n/bundleIdn/fileNamej\n\n\n\n\nwhere \nbundleId\n and \nfileName\n are the original \nBundle ID\n and file name of the file respectively. It possible to control the layout using the \n--layout\n option. Using \n--layout object-id\n will instead produce a flat list of files named by their associated Object ID.\n\n\nThe file system implementation's performance is optimized for serial reads. Frequent random access patterns will lead to very poor performance. Under the covers, each random seek requires a new HTTP connection to S3 with the appropriate \nRange\n header set which is an expensive operation. For this reason, it is only recommended for streaming analysis (e.g. \nsamtools view\n like functionality).\n\n\nMount All Files\n\n\nTo mount all available files locally, issue the following:\n\n\n# Create the mount point\nmkdir /mnt/icgc\n\n# Mount\nbin/icgc-storage-client mount --mount-point /mnt/icgc\n\n\n\n\nTo speed up subsequent mounts, one can specify the \n--cache-metadata\n flag above which will locally store an index of the file system.\n\n\nOnce mounted, you can use standard analysis tools against files found under the mount point:\n\n\n# Slice\nsamtools view /mnt/icgc/fff75930-0f8c-4c99-9b48-732e7ed4c625/443a7a6ab964e41c011cc9a303bc086c.bam 1:10000-20000\n\n\n\n\nMount Only Manifest Entries\n\n\nTo filter the mount to only include the files specified in a Manifest, issue the following:\n\n\n# Create the mount point\nmkdir /mnt/icgc\n\n# Mount\nbin/icgc-storage-client mount --mount-point /mnt/icgc --manfiest manifest\n\n\n\n\n\nSee the \nmanifest\n command for more details on how to specify a Manifest.\n\n\nMount in Docker\n\n\nTo avoid having to install the FUSE and Java dependencies when working with the \nmount\n command, it is very convenient to mount from within a Docker container. This is also useful for creating a custom image for analysis that derives from the one published by ICGC. First, ensure that Docker and the Storage Client image is installed. See the \nInstallation\n section for details.\n\n\nNext, export the access token generated from the portal:\n\n\n# Export access token\nexport ACCESSTOKEN=accessToken\n\n\n\n\n\nAnd then mount the file system inside the container against the empty \n/mnt\n directory:\n\n\n# Alias for ease of use\nalias icgc-storage-client=\ndocker run -it --rm -e ACCESSTOKEN --privileged icgc/icgc-storage-client bin/icgc-storage-client\n\n\n\n\n\n# Mount the file system in the container\nicgc-storage-client mount --mount-point /mnt\n\n\n\n\nNote that the \n--privileged\n Docker option is required for FUSE in order to access the host's \n/dev/fuse\n device.\n\n\nIn another terminal, you can access the newly mounted file system:\n\n\n# List all files recursively\ndocker exec -it $(docker ps -lq) find /mnt\n\n\n\n\nTo perform analysis within the container:\n\n\n# Open a shell in the previously created container\ndocker exec -it $(docker ps -lq) bash\n\n# Install samtools\napt-get install samtools\n\n# Slice\nsamtools view /mnt/fff75930-0f8c-4c99-9b48-732e7ed4c625/443a7a6ab964e41c011cc9a303bc086c.bam 1:10000-20000\n\n\n\n\nDue to a limitation of Docker it is not possible to access a FUSE mounted file system from the host operating system. Please see \nhere\n for more details.\n\n\nFAQs\n\n\nWhere can I find the Bundle ID associated with an Object ID?\n\n\nCurrently the only way to retrieve the Bundle ID of an Object ID is by viewing the file entity page in the Data Portal. Navigate to the Data Repository browser and enter the Object ID in the \"File\" filter and click on the resulting record.\n\n\nWhere are detailed Storage Client logs stored?\n\n\nThe Storage Client log file is stored at \nlogs/client.log\n\n\nHow long will pre-signed URLs remain valid?\n\n\nPre-signed URLs are valid for 1 day from the time they are issued. For security purposes, a URL issued to one user must not be used by another and must be kept private.\n\n\nDoes the client maintain state?\n\n\nYes, the client maintains state in the working directory in a hidden file \n.\nspan class=\"token operator\"\n/span\nObject ID\nspan class=\"token operator\"\n/span\n/meta\n. This file includes cached pre-signed URLS. If your downloads fail unexpectedly, then try deleting this directory to purge pre-signed URLs that may have expired. Also, when using the \nmount\n command with the \n--cache-metadata\n option, \n.entities.cache\n and \n.objects.cache\n are stored in the current working directory.\n\n\nWhy do I get a security exception when I try to download an object?\n\n\nIf you are targeting the AWS cloud, ensure that you are running within the \nus-east-1\n \nregion\n. If you are targeting Collaboratory, make sure you are inside the OpenStack environment.\n\n\nI can\u2019t use the result of a \nurl\n command with \nsamtools\n:\n\n\nsamtools\n doesn\u2019t support the HTTPS protocol\n*\n, which is required by ICGC to access S3-stored data files. Use the client \nview\n command to pipe data to samtools, download the desired files locally, or use the mount command to create a FUSE mount of the ICGC data files.\n\n\n*\n \nUpdate\n: As of commit \nfe1f08a\n \nsamtools\n now supports file access over HTTPS and Amazon S3.\n\n\nHow do I report a bug in the software?\n\n\nPlease contact \ndcc-support@icgc.org\n and include the version of the software in the body of the message (\nbin/icgc-storage-client --version\n).\n\n\nTerms\n\n\nRelated terms and their defintions are given below:\n\n\n\n\n\n\n\n\nTerm\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\nAccess Token\n\n\nAn authorization mechanism created by the \nData Portal\n to access data.\n\n\n\n\n\n\nBundle ID\n\n\nAn identifier that refers to a submission bundle of related files. Typically the files produced by analysis workflows are packaged as a single unit. However, when a bundle is imported into a cloud repository each file in the bundle is given its own Object ID.\n\n\n\n\n\n\nCompute Instance\n\n\nA user virtual machine operating in a cloud environment.\n\n\n\n\n\n\nDACO\n\n\nThe Data Access Compliance Office which handles requests from researchers for access to controlled data from the ICGC.\n\n\n\n\n\n\nDACO Cloud Access\n\n\nDACO access with supplemental approved Cloud Access status.\n\n\n\n\n\n\nDCC\n\n\nThe ICGC Data Coordination Center (\nDCC\n) performs quality assessment, curation and data releases and also manages the data flow from projects and centers to the central ICGC database and public repositories.\n\n\n\n\n\n\nData Portal\n\n\nThe ICGC data portal located at \nhttps://dcc.icgc.org\n.\n\n\n\n\n\n\nFUSE\n\n\nFilesystem in Userspace\n is an operating system mechanism for Unix-like computer operating systems that lets non-privileged users create their own file systems without editing kernel code.\n\n\n\n\n\n\nManifest\n\n\nA file used as input to the Storage Client to describe and identify files to be downloaded.\n\n\n\n\n\n\nObject ID\n\n\nThe unique identifier of an object expressed as a UUID. In the command line interface this is refered to as \n--object-id\n.\n\n\n\n\n\n\nOpenStack\n\n\nOpenStack is a cloud operating system that controls large pools of compute, storage, and networking resources throughout a datacenter, all managed through a dashboard that gives administrators control while empowering their users to provision resources through a web interface.\n\n\n\n\n\n\nScope\n\n\nA user permission or authorization to access a resource.\n\n\n\n\n\n\nStorage Client\n\n\nSofware provided by ICGC required to download data from AWS S3.\n\n\n\n\n\n\nS3\n\n\nAmazon Simple Storage Service\n, the physical store of the ICGC AWS data.\n\n\n\n\n\n\nToken Manager\n\n\nSection of the portal used to manage Access Tokens.", 
            "title": "Guide"
        }, 
        {
            "location": "/cloud/guide/#overview", 
            "text": "This user guide describes the steps to securely explore and analyze ICGC data stored in  Amazon ( AWS )  or  Collaboratory ( OpenStack )  cloud environments. For more information about ICGC cloud initiatives, please see  ICGC in the Cloud .  Please see  Terms  for a glossary of terms used in this guide.  Process  The figure below illustrates the overall process and systems involved:   Authorization \n    Apply for DACO  Cloud Access  if not already approved\n    Upon approval, login to the  Data Portal \n    Generate an  Access Token  for cloud download  Compute Prerequistes \n    Provision a  Compute Instance  in the target cloud  Installation \n    Download and install the ICGC  Storage Client  Configuration \n    Configure the Storage Client to use the generated Access Token  File Search \n    Identify files of interest using the Data Portal  Storage Client Usage \n    Download or view data with the provided Storage Client or via an external tool    The subsequent sections will provide additional details on each of these topics.  Security  The usage of the distributed  Storage Client  is required to provide additional security while operating in participating cloud environments and to enhance user download speeds.  AWS  Security is enforced by a coordinating ICGC storage server. The client communicates with the server which brokers downloads and converts ICGC Access Tokens into Amazon  pre-signed urls . Once a successful authorization handshake between the client and the server is established, downloads will be transferred directly from  S3  to the client, maintaining fast access to the data.  It is important to note that the provided software only functions within the  us-east-1  EC2 region of AWS located in Northern Virginia, U.S. where the data is physically stored. Attempting to use the software outside of this region will be denied data access.  Collaboratory  Downloads only function inside Collaboratory's OpenStack environment.  Lastly, it is the user\u2019s responsibility to protect the data after it has been attained. This includes any subsequent analyses and storage on cloud and downstream resources.", 
            "title": "Overview"
        }, 
        {
            "location": "/cloud/guide/#authorization", 
            "text": "There are two prerequesites to using the Storage Client: DACO Cloud Access status and a self-provisioned Access Token.  DACO Cloud Access  DACO Cloud Access is prerequisite to using the Storage Client. To apply for DACO access please follow the instructions provided at  https://icgc.org/daco . Once approved, you will be able to  login  to the Data Portal to generate an  Access Token . To login, click on the \u201cLogin\u201d link in the upper right-hand corner of the page. When prompted, choose to login with either your  ICGC.org login  or one of the supported OpenID providers (e.g. Google). After successful authentication, you will know that you have Cloud Access to the controlled tier if the \u201clogin\u201d link is replaced with a green cloud icon ().  Access Tokens  The Access Token model used for protecting the cloud data set follows a similar process to Github\u2019s  personal access tokens . Tokens are used instead of a username / password to securely access ICGC resources.  Related to Access Tokens is the concept of  Scopes . Tokens allow you to associate Scopes which limit access to that needed for the target environment. This enhances security by following the  Principle of Least Privilege . Cloud specific Scopes will become available after acquiring DACO Cloud Access. An instance of a cloud download token will grant access to all of the available data in that environment.  Token Manager  To acquire an Access Token, you must first obtain DACO Clould Access and login to the Data Portal. After a successful login, there will be  Token Manager  link in the upper right corner of the page. Clicking on this link will display the Token Manager dialog:   From this dialog, you can manage the Access Tokens associated with your account. Importantly, you may delete and regenerate an access token if you believe that it has been compromised.   When creating an Access Token, you will need to specify the Scope associated with the target cloud(s).  AWS  In the case of the ICGC AWS data set, an access token with the  aws.download  scope is required to access the  controlled access data  Collaboratory  In the case of the ICGC Collaboratory data set, an access token with the  collab.download  scope is required to access the  controlled access data  You can verify that your Access Token has the desired scopes by inspecting it in the table at the bottom of the dialog. For security purposes, Access Tokens must remain private and not be shared with anyone.  Following the creation of a Compute Instance, discussed in the next section, you will need to edit the Storage Client client configuration file to include the generated Access Token. See the  Configuration  section for additional information.", 
            "title": "Authorization"
        }, 
        {
            "location": "/cloud/guide/#compute-prerequisites", 
            "text": "Compute Instance  As a first step in analyzing data, you will need to create a Compute Instance to run the Storage Client and any other supporting software.  AWS  In order to run within  EC2 , you will need your own AWS account to provision a running EC2 instance. Any data processing will be charged to this account. Note that ICGC data download from S3 to the same EC2 region is free of charge. Please see Amazon's documentation for detailed instructions.  Collaboratory  In order to run within  Collaboratory , you will need to be enrolled. To begin the enrollment process, please send an email to  help@cancercollaboratory.org .  The following sections provide guidance on selecting and configuring the chosen instance type.  Resources  As data files are quite large, users should have enough local disk space to store files downloaded from the remote repository.  More processing cores will give greater parallelism, and therefore, better thoughput of downloads.  By default the storage client is configured to use a maximum of 3G of RAM. Most of time this is more than sufficient.  Operating System  The Storage Client has been designed to work on modern Mac and Linux distributions. Windows should work as well but remains untested.  Dependencies  The Storage Client requires Java 8 to be installed. It has been tested using the Oracle distribution. The procedure for installing Java 8 will vary depending on the operating system and package manager used.  In order to use the mount feature,  FUSE  is required. On most Linux based systems this will require installing  libfuse-dev  and  fuse  packages.", 
            "title": "Compute Prerequisites"
        }, 
        {
            "location": "/cloud/guide/#installation", 
            "text": "This section describes how to install the Storage Client. The are two options: (a) from a tarball and (b) from a Docker image hosted on Dockerhub.  Install from Tarball  To begin using the Storage Client, the first step is to download the distribution. The latest version can be downloaded from  here .  wget -O icgc-storage-client.tar.gz https://dcc.icgc.org/api/v1/ui/software/icgc-storage-client/latest\ntar -xvzf icgc-storage-client.tar.gz  After untaring the archive, the Storage Client will be available at  bin/icgc-storage-client . Steps to verify the authenticity and integrity of the download can be found on our  software  page.  Install from Docker Image  We also support a Docker image of the Storage Client that is bundled with Java 8 for easy deployment.  The image is hosted at  https://hub.docker.com/r/icgc/icgc-storage-client/  and downloaded by issuing the following command:  docker pull icgc/icgc-storage-client  Once pulled, you can open a shell in the container by executing:  docker run -it icgc/icgc-storage-client  There is no entry point or command defined for the image. The software may be located at  /icgc/icgc-storage-client  which is also the working directory of the container. All other steps for  using the Storage Client  will be the same for both Docker and tarball installations.", 
            "title": "Installation"
        }, 
        {
            "location": "/cloud/guide/#configuration", 
            "text": "The configuration of the Storage Client is stored in the  conf/application.properties  file of the distribution.  Access Configuration  The main configuration element is the access token generated in  Access Token  above. Configuration is stored in the  conf/  directory of the distribution.  Edit  application.properties  and add the generated accesss token to the line:  accessToken=access token  When using Docker, this can also be set with an environmental variable:  docker run -it -e ACCESSTOKEN=access token icgc/icgc-storage-client  Collaboratory  In addition to the above, you will need to change the  bin/icgc-storage-client  script to set  STORAGE_PROFILE=collab . This can also performed externally via the environmental variable of the same name. Note that it is also possible to override this per execution using  bin/icgc-storage-client 's  --profile collab  argument.  Transport Configuration  Based on the target Compute Instance defined in  Compute Prerequisites  and transfer speed requirements, it may be necessary to make changes to how the Storage Client transfers data. This is achieved by setting  transport.parallel  and  transport.memory :   transport.parallel  controls the number of concurrent threads for multi-part data transfers. It is recommended to set this to the number of cores of the Compute Instance.  transport.memory  is the amount of non-heap memory per thread, in gigabytes. It is recommended set this to a value of  1  (1 GB). Be sure to leave enough memory for the operating system and any other software that may be running on the Compute Instance.", 
            "title": "Configuration"
        }, 
        {
            "location": "/cloud/guide/#file-search", 
            "text": "Finding files of interest can be done via the Data Portal. Objects are identified by their  Object ID .   Navigate to  repository file search  Click on the  AWS  or  Collaboratory  filter in the left hand pane  Filter based on properties of interest (e.g. donor id, specimen id, etc.)  Export a  Manifest  for future use with the Storage Client   The Manifest is the main way to define what files should be downloaded by the Storage Client. However, knowing the Object ID is sufficient for a single file download. To generate a Manifest, click on the \"Download manifests\" link the the Data Repository browser. You will be prompted with a \"Download manifests\" dialog:   Manifests downloaded from the Data Portal can be transferred to the Storage Client instance by using SFTP or SCP. For convenience, it is also possible to use a Manifest ID saved on the Data Portal by clicking on the \"Manifest ID\" button. See the  Storage Client Usage  section for usage information.", 
            "title": "File Search"
        }, 
        {
            "location": "/cloud/guide/#storage-client-usage", 
            "text": "This section provides information on how to use the Storage Client once it has been properly downloaded and configured. It assumes the user possesses and has configured the requisite access token discussed previously.  The Storage Client has the general syntax:  icgc-storage-client [options] [command] [command options]  It offers a set of commands, where each command has its own set of options to influence its operation.  Help  The Storage Client provides a  --help  option to list the available commands and a brief description of their supported options:  bin/icgc-storage-client --help  It is also possible to get information on a specific command using the  help  command:  bin/icgc-storage-client help download  URL Command  The  url  command is the most basic command supported by the Storage Client. It allows one to resolve the underyling S3 URL for the requested object. This is useful if one wants to directly access the URL via HTTPS with an external client or tool (e.g.  curl ,  wget , etc.)  bin/icgc-storage-client url --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd  An example of using  wget :  bin/icgc-storage-client url --object-id Object ID\nResolving URL for object: ddcdd044-adda-5f09-8849-27d6038f8ccd (offset = 0, length = -1)\nhttps://s3-external-1.amazonaws.com/snip \n\nwget https://s3-external-1.amazonaws.com/snip   Download Command  The  download  command allows fast parallel download of remote objects. It can be run in one of two modes: (a) single object mode and (b) Manifest driven mode  Note that the Storage Client is able to resume an interrupted download session. Simply rerun the same command again and it will continue.  Single Object  This mode is most useful when downloading a single object given a known Object ID, perhaps acquired from the Data Portal:  bin/icgc-storage-client download --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd --output-dir data  Downloads will be stored in the  --output-dir .  Manifest  Using a Manifest is ideal for downloading multiple files identified through the Data Portal. The  repository file search  allows one to generate a Manifest file that can be supplied for bulk downloading files. It also provides some additional metadata for selected files that gives the donor, specimen and sample context.  bin/icgc-storage-client download --manifest manifest.txt --output-dir data  The optional  --output-layout  option can be used to organize the downloads into a couple of predefined directory layouts. See the  --help  for addional information.  Manifest Command  The  manifest  command allows a user to quickly view the contents of a download Manifest produced by the Data Portal. A Manifest can come from:   The local file system  A Manifest ID that is hosted on the Data Portal  Any URL   A Manifest is a TSV file that contains both file identifying fields and satellite metadata for understanding the relationships to other data including donor, project and study.  Manifest from a Local File  An example of using a local file system Manifest:  bin/icgc-storage-client manifest --manifest manifest.aws-virginia.1444232116728.txt  Manifest from the Data Portal  An example of using a Data Portal hosted Manifest:  bin/icgc-storage-client manifest --manifest 49e91614-7811-11e5-8a58-34363bcf803c  Manifest from a URL  An example of using a URL hosted Manifest:  bin/icgc-storage-client manifest --manifest http://hastebin.com/raw/ujajodilih  View Command  The  view  command is a minimal version of  samtools view . It allows to request a \u201cgenomic slice\u201d of the remote BAM file, freeing the user from having to download the entire file locally, saving bytes and time.  The following example will download reads overlapping the region 1 - 100000 in chromosome 1:  bin/icgc-storage-client view --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd --query 1:1-100000  The BAI is automatically discovered and streamed as part of the operation.  For quickly accessing the only the BAM header one can issue:  bin/icgc-storage-client view --header-only --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd  It is also possible to pipe the output of the above to  samtools , etc. for pipelining a workflow:  bin/icgc-storage-client view --object-id ddcdd044-adda-5f09-8849-27d6038f8ccd | samtools mpileup -  Mount Command  The  mount  command can be used to mount the remote S3 bucket as a read-only  FUSE  file system. This is very useful to browse and explore the available files, as well as quickly see their size and date of modification using common commands such as  ls ,  find ,  du  and  tree . It also works very well with standard analysis tools such as  samtools .  Files are organized into a virtual directory structure. The following shows the default  bundle  layout:  /bundleId1/fileName1\n/bundleId1/fileName2\n...\n/bundleId1/fileNamei\n...\n/bundleIdn/fileName1\n/bundleIdn/fileName2\n...\n/bundleIdn/fileNamej  where  bundleId  and  fileName  are the original  Bundle ID  and file name of the file respectively. It possible to control the layout using the  --layout  option. Using  --layout object-id  will instead produce a flat list of files named by their associated Object ID.  The file system implementation's performance is optimized for serial reads. Frequent random access patterns will lead to very poor performance. Under the covers, each random seek requires a new HTTP connection to S3 with the appropriate  Range  header set which is an expensive operation. For this reason, it is only recommended for streaming analysis (e.g.  samtools view  like functionality).  Mount All Files  To mount all available files locally, issue the following:  # Create the mount point\nmkdir /mnt/icgc\n\n# Mount\nbin/icgc-storage-client mount --mount-point /mnt/icgc  To speed up subsequent mounts, one can specify the  --cache-metadata  flag above which will locally store an index of the file system.  Once mounted, you can use standard analysis tools against files found under the mount point:  # Slice\nsamtools view /mnt/icgc/fff75930-0f8c-4c99-9b48-732e7ed4c625/443a7a6ab964e41c011cc9a303bc086c.bam 1:10000-20000  Mount Only Manifest Entries  To filter the mount to only include the files specified in a Manifest, issue the following:  # Create the mount point\nmkdir /mnt/icgc\n\n# Mount\nbin/icgc-storage-client mount --mount-point /mnt/icgc --manfiest manifest   See the  manifest  command for more details on how to specify a Manifest.  Mount in Docker  To avoid having to install the FUSE and Java dependencies when working with the  mount  command, it is very convenient to mount from within a Docker container. This is also useful for creating a custom image for analysis that derives from the one published by ICGC. First, ensure that Docker and the Storage Client image is installed. See the  Installation  section for details.  Next, export the access token generated from the portal:  # Export access token\nexport ACCESSTOKEN=accessToken   And then mount the file system inside the container against the empty  /mnt  directory:  # Alias for ease of use\nalias icgc-storage-client= docker run -it --rm -e ACCESSTOKEN --privileged icgc/icgc-storage-client bin/icgc-storage-client   # Mount the file system in the container\nicgc-storage-client mount --mount-point /mnt  Note that the  --privileged  Docker option is required for FUSE in order to access the host's  /dev/fuse  device.  In another terminal, you can access the newly mounted file system:  # List all files recursively\ndocker exec -it $(docker ps -lq) find /mnt  To perform analysis within the container:  # Open a shell in the previously created container\ndocker exec -it $(docker ps -lq) bash\n\n# Install samtools\napt-get install samtools\n\n# Slice\nsamtools view /mnt/fff75930-0f8c-4c99-9b48-732e7ed4c625/443a7a6ab964e41c011cc9a303bc086c.bam 1:10000-20000  Due to a limitation of Docker it is not possible to access a FUSE mounted file system from the host operating system. Please see  here  for more details.", 
            "title": "Storage Client Usage"
        }, 
        {
            "location": "/cloud/guide/#faqs", 
            "text": "Where can I find the Bundle ID associated with an Object ID?  Currently the only way to retrieve the Bundle ID of an Object ID is by viewing the file entity page in the Data Portal. Navigate to the Data Repository browser and enter the Object ID in the \"File\" filter and click on the resulting record.  Where are detailed Storage Client logs stored?  The Storage Client log file is stored at  logs/client.log  How long will pre-signed URLs remain valid?  Pre-signed URLs are valid for 1 day from the time they are issued. For security purposes, a URL issued to one user must not be used by another and must be kept private.  Does the client maintain state?  Yes, the client maintains state in the working directory in a hidden file  . span class=\"token operator\" /span Object ID span class=\"token operator\" /span /meta . This file includes cached pre-signed URLS. If your downloads fail unexpectedly, then try deleting this directory to purge pre-signed URLs that may have expired. Also, when using the  mount  command with the  --cache-metadata  option,  .entities.cache  and  .objects.cache  are stored in the current working directory.  Why do I get a security exception when I try to download an object?  If you are targeting the AWS cloud, ensure that you are running within the  us-east-1   region . If you are targeting Collaboratory, make sure you are inside the OpenStack environment.  I can\u2019t use the result of a  url  command with  samtools :  samtools  doesn\u2019t support the HTTPS protocol * , which is required by ICGC to access S3-stored data files. Use the client  view  command to pipe data to samtools, download the desired files locally, or use the mount command to create a FUSE mount of the ICGC data files.  *   Update : As of commit  fe1f08a   samtools  now supports file access over HTTPS and Amazon S3.  How do I report a bug in the software?  Please contact  dcc-support@icgc.org  and include the version of the software in the body of the message ( bin/icgc-storage-client --version ).", 
            "title": "FAQs"
        }, 
        {
            "location": "/cloud/guide/#terms", 
            "text": "Related terms and their defintions are given below:     Term  Meaning      Access Token  An authorization mechanism created by the  Data Portal  to access data.    Bundle ID  An identifier that refers to a submission bundle of related files. Typically the files produced by analysis workflows are packaged as a single unit. However, when a bundle is imported into a cloud repository each file in the bundle is given its own Object ID.    Compute Instance  A user virtual machine operating in a cloud environment.    DACO  The Data Access Compliance Office which handles requests from researchers for access to controlled data from the ICGC.    DACO Cloud Access  DACO access with supplemental approved Cloud Access status.    DCC  The ICGC Data Coordination Center ( DCC ) performs quality assessment, curation and data releases and also manages the data flow from projects and centers to the central ICGC database and public repositories.    Data Portal  The ICGC data portal located at  https://dcc.icgc.org .    FUSE  Filesystem in Userspace  is an operating system mechanism for Unix-like computer operating systems that lets non-privileged users create their own file systems without editing kernel code.    Manifest  A file used as input to the Storage Client to describe and identify files to be downloaded.    Object ID  The unique identifier of an object expressed as a UUID. In the command line interface this is refered to as  --object-id .    OpenStack  OpenStack is a cloud operating system that controls large pools of compute, storage, and networking resources throughout a datacenter, all managed through a dashboard that gives administrators control while empowering their users to provision resources through a web interface.    Scope  A user permission or authorization to access a resource.    Storage Client  Sofware provided by ICGC required to download data from AWS S3.    S3  Amazon Simple Storage Service , the physical store of the ICGC AWS data.    Token Manager  Section of the portal used to manage Access Tokens.", 
            "title": "Terms"
        }, 
        {
            "location": "/submission/about/", 
            "text": "About\n\n\nOverview\n\n\nThis is the documentation page for the ICGC submission system", 
            "title": "About"
        }, 
        {
            "location": "/submission/about/#about", 
            "text": "", 
            "title": "About"
        }, 
        {
            "location": "/submission/about/#overview", 
            "text": "This is the documentation page for the ICGC submission system", 
            "title": "Overview"
        }, 
        {
            "location": "/submission/access/", 
            "text": "Access\n\n\nOverview\n\n\nThis is the Access documentation page", 
            "title": "Access"
        }, 
        {
            "location": "/submission/access/#access", 
            "text": "", 
            "title": "Access"
        }, 
        {
            "location": "/submission/access/#overview", 
            "text": "This is the Access documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/submission/api/", 
            "text": "API\n\n\nOverview\n\n\nThis is the API documentation page", 
            "title": "API"
        }, 
        {
            "location": "/submission/api/#api", 
            "text": "", 
            "title": "API"
        }, 
        {
            "location": "/submission/api/#overview", 
            "text": "This is the API documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/submission/dictionary/", 
            "text": "Dictionary\n\n\nOverview\n\n\nThis is the Dictionary documentation page", 
            "title": "Dictionary"
        }, 
        {
            "location": "/submission/dictionary/#dictionary", 
            "text": "", 
            "title": "Dictionary"
        }, 
        {
            "location": "/submission/dictionary/#overview", 
            "text": "This is the Dictionary documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/submission/guide/", 
            "text": "Guide\n\n\nOverview\n\n\nThere are five major steps in the data submission process:\n\n\n\n\nObtain login/password account from EGA's \nEBI\n repository/\n\n\nSubmit raw sequence data to the European Genome-phenome Archive\n\n\nPrepare the ICGC submission files according to DCC data format specifications\n\n\nSubmit files to the DCC Secure FTP server\n\n\nValidate submission files using web-based submission system\n\n\n\n\nFor Release 15, all submitted data must be based on \nHuman reference genome assembly\n \nGRCh37\n and \nEnsembl gene set\n \nversion 69\n.\n\n\nWhen submitting experimental data to the ICGC DCC, please make sure you've already deposited your raw data to the appropriate public data repositories (eg: sequencing reads to EBI EGA). You will need to populate the data elements \nraw_data_repository\n and \nraw_data_accession\n with the correct repository and accession number respectively.\n\n\nPlease contact the DCC (\n_dcc-support@icgc.org\n) if you have any questions or comments about the data submission process._\n\n\nNIGHT MODE", 
            "title": "Guide"
        }, 
        {
            "location": "/submission/guide/#guide", 
            "text": "", 
            "title": "Guide"
        }, 
        {
            "location": "/submission/guide/#overview", 
            "text": "There are five major steps in the data submission process:   Obtain login/password account from EGA's  EBI  repository/  Submit raw sequence data to the European Genome-phenome Archive  Prepare the ICGC submission files according to DCC data format specifications  Submit files to the DCC Secure FTP server  Validate submission files using web-based submission system   For Release 15, all submitted data must be based on  Human reference genome assembly   GRCh37  and  Ensembl gene set   version 69 .  When submitting experimental data to the ICGC DCC, please make sure you've already deposited your raw data to the appropriate public data repositories (eg: sequencing reads to EBI EGA). You will need to populate the data elements  raw_data_repository  and  raw_data_accession  with the correct repository and accession number respectively.  Please contact the DCC ( _dcc-support@icgc.org ) if you have any questions or comments about the data submission process._  NIGHT MODE", 
            "title": "Overview"
        }, 
        {
            "location": "/submission/methods/", 
            "text": "Methods\n\n\nOverview\n\n\nThis is the Methods documentation page", 
            "title": "Methods"
        }, 
        {
            "location": "/submission/methods/#methods", 
            "text": "", 
            "title": "Methods"
        }, 
        {
            "location": "/submission/methods/#overview", 
            "text": "This is the Methods documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/submission/software/", 
            "text": "Software\n\n\nOverview\n\n\nThis is the Software documentation page\n\n\nRelease Notes\n\n\nChanges in Submission System Software Release 3.6.1.1 - October 10, 2014\n\n\n\n\nAdded \"header-only file validation\" to inform the user of an unintended empty submission file\n\n\nAdded \"sample type validation\" to verify that samples referenced in meta file \nanalyzed_sample_id\n, \nmatched_sample_id\n and \nreference_sample_type\n fields are consistent with the \nspecimen_type\n field found in the associated specimen files.\n\n\n\n\nChanges in Submission System Software Release 2.6 - March 17, 2014\n\n\n\n\nIncremental data submission. Users can now manage their data submission directory and upload only new data. Please see \nhere\n for more information\n\n\nSupport multiple files. Data can be split in multiple files per data type\n\n\nSelective data validation. Users can now validate data by data type and not anymore the whole submission each time.\n\n\nNew user interface\n\n\nFaster validation engine\n\n\nMany bug fixes\n\n\n\n\nFor more information, please see the Submission System Guide available \n here \n. Please don't hesitate to contact us at \ndcc-support@icgc.org\n if you have any questions or to report any bugs.\n\n\nSincerely,\nThe DCC team.\n\n\nNIGHT MODE", 
            "title": "Software"
        }, 
        {
            "location": "/submission/software/#software", 
            "text": "", 
            "title": "Software"
        }, 
        {
            "location": "/submission/software/#overview", 
            "text": "This is the Software documentation page", 
            "title": "Overview"
        }, 
        {
            "location": "/submission/software/#release-notes", 
            "text": "Changes in Submission System Software Release 3.6.1.1 - October 10, 2014   Added \"header-only file validation\" to inform the user of an unintended empty submission file  Added \"sample type validation\" to verify that samples referenced in meta file  analyzed_sample_id ,  matched_sample_id  and  reference_sample_type  fields are consistent with the  specimen_type  field found in the associated specimen files.   Changes in Submission System Software Release 2.6 - March 17, 2014   Incremental data submission. Users can now manage their data submission directory and upload only new data. Please see  here  for more information  Support multiple files. Data can be split in multiple files per data type  Selective data validation. Users can now validate data by data type and not anymore the whole submission each time.  New user interface  Faster validation engine  Many bug fixes   For more information, please see the Submission System Guide available   here  . Please don't hesitate to contact us at  dcc-support@icgc.org  if you have any questions or to report any bugs.  Sincerely,\nThe DCC team.  NIGHT MODE", 
            "title": "Release Notes"
        }
    ]
}